{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import BatchIterator\n",
    "from lasagne.layers import InputLayer, Conv2DLayer, DropoutLayer,\\\n",
    "    MaxPool2DLayer, DenseLayer\n",
    "from lasagne.nonlinearities import softmax, sigmoid\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from utils import FactorizeActors, ProcessIMDBData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = ProcessIMDBData('data/imdb.csv', ['genres', 'movie_imdb_link', 'color'])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df['imdb_score']\n",
    "df.drop('imdb_score', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = x = df.values\n",
    "ys = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Matriz de Correlaci√≥n Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a = df.corr()\n",
    "\n",
    "df_corr = df[a.columns.tolist()]\n",
    "\n",
    "plt.matshow(df_corr.corr())\n",
    "plt.xticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist(), rotation=\"vertical\")\n",
    "plt.yticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import RandomizedPCA # using randomized Singular Value Decomposition \n",
    "Xp = RandomizedPCA(n_components=35, random_state=1)\n",
    "Xp = Xp.fit_transform(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Xp.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def plot_matrix(clf, X_test, y_test):\n",
    "    plt.clf()\n",
    "    plt.imshow(confusion_matrix(clf.predict(X_test), y_test),\n",
    "               interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"true label\")\n",
    "    plt.ylabel(\"predicted label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=300,\n",
    "                           max_features=0.2, \n",
    "                           n_jobs=2,\n",
    "                           max_depth=None,\n",
    "                           min_samples_split=1,\n",
    "                           random_state=1).fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print(\"Score over Testing Data {}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Score over Training Data {}\".format(clf.score(X_train, y_train)))\n",
    "plot_matrix(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se guardan scores y labels verdaderos del ExtraTreesClassifier\n",
    "y_true_tree = y_test\n",
    "scores_tree = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "cols = len(df.columns)\n",
    "\n",
    "text = list(map(lambda i: df.columns[i], range(cols)))\n",
    "plt.figure(figsize=(20,cols))\n",
    "print(importances[::-1].shape)\n",
    "plt.bar(range(cols),height=importances,  width=1.)\n",
    "plt.xticks(np.arange(0.5, cols, 1.), text, rotation=90)\n",
    "plt.xlim((0, cols))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(random_state=0).fit(X_train, y_train)\n",
    "#print clf.score(X_test, y_test)\n",
    "plot_matrix(clf, X_test, y_test)\n",
    "clf.score(X_test, y_test)\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "sv = SVC(kernel='rbf', cache_size=1000)\n",
    "sv.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, sv.predict(X_test)))\n",
    "print(sv.score(X_test, y_test))\n",
    "plot_matrix(sv, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, sv.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true_svm = y_test\n",
    "scores_svm = sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.nonlinearities import linear, tanh, rectify\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = x\n",
    "ys = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_x = MinMaxScaler([-1, 1])\n",
    "xs = std_x.fit_transform(np.array(xs))\n",
    "std_y = MinMaxScaler([0, 2])\n",
    "ys = std_y.fit_transform(np.array(ys))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers_0 = [\n",
    "                (InputLayer, {'shape': (None, 50)}),\n",
    "                (DenseLayer, {'num_units': 512}),\n",
    "                (DropoutLayer, {'p': 0.5}),\n",
    "                (DenseLayer, {'num_units': 512}),\n",
    "                (DropoutLayer, {'p': 0.5}),\n",
    "                (DenseLayer, {'num_units': 3, 'nonlinearity': softmax}),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdjustVariable(object):\n",
    "    \"\"\"\n",
    "    Used to decreases linearly the learning rate with the number of epochs,\n",
    "    while we the momentum increase.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = np.float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_network(npochs=50, batch_s=10000):\n",
    "    return NeuralNet(\n",
    "        layers=layers_0,\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=theano.shared(np.float32(0.009)),\n",
    "        update_momentum=theano.shared(np.float32(0.9)),\n",
    "\n",
    "        regression=False,\n",
    "        batch_iterator_train=BatchIterator(batch_size=batch_s),\n",
    "        on_epoch_finished=[\n",
    "            AdjustVariable('update_learning_rate', start=0.09, stop=0.009),\n",
    "            AdjustVariable('update_momentum', start=0.9, stop=0.9999)\n",
    "        ],\n",
    "        max_epochs=npochs,\n",
    "        verbose=1)\n",
    "\n",
    "#net0 = create_network(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net0 = create_network(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.int32)\n",
    "\n",
    "net0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "def plot_loss_net(net0):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(15,5))\n",
    "\n",
    "    train_loss = np.array([i[\"train_loss\"] for i in net0.train_history_])\n",
    "    valid_loss = np.array([i[\"valid_loss\"] for i in net0.train_history_])\n",
    "    plt.plot(train_loss, '--b', linewidth=2, label=\"{} train\".format(\"net0\"))\n",
    "    plt.plot(valid_loss, '-b', linewidth=2, label=\"{} valid\".format(\"net0\"))\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_loss_net(net0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "print(classification_report(y_test, net0.predict(X_test)))\n",
    "plot_matrix(net0, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, net0.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Curva ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_color_plt(i):\n",
    "    color = \"\"\n",
    "    if i == 0:\n",
    "        color = 'darkorange'\n",
    "    elif i == 1:\n",
    "        color = 'blue'\n",
    "    elif i== 2: \n",
    "        color = 'green'\n",
    "    elif i == 3:\n",
    "        color = 'red'\n",
    "    return color\n",
    "\n",
    "# Ploteo para cada una de las clases\n",
    "def plotear_grafico_roc(lista_fpr,lista_tpr,lista_nombres):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    for i in range(0,len(lista_fpr)):\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        roc_auc = dict()\n",
    "        print (lista_fpr[i])\n",
    "        roc_auc[0] = auc(lista_fpr[i], lista_tpr[i])\n",
    "        color = get_color_plt(i)\n",
    "        plt.plot(lista_fpr[i], lista_tpr[i], color=color,\n",
    "                 lw=lw,\n",
    "                 label='ROC curve (%s, area = %0.2f)' % (lista_nombres[i],roc_auc[0]))\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_true_net = y_test\n",
    "scores_net = net0.predict(X_test)\n",
    "fpr_net, tpr_net, thresholds = roc_curve(y_true_net, scores_net, pos_label=2)\n",
    "fpr_svm, tpr_svm, thresholds = roc_curve(y_true_svm, scores_svm, pos_label=2)\n",
    "fpr_tree, tpr_tree, thresholds = roc_curve(y_true_tree, scores_tree, pos_label=2)\n",
    "\n",
    "\n",
    "plotear_grafico_roc([fpr_net,fpr_svm,fpr_tree],[tpr_net,tpr_svm,tpr_tree],['ANN','SVC','TreeClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
