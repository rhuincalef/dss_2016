{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import BatchIterator\n",
    "from lasagne.layers import InputLayer, Conv2DLayer, DropoutLayer,\\\n",
    "    MaxPool2DLayer, DenseLayer\n",
    "from lasagne.nonlinearities import softmax, sigmoid\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agrupar_pelis(x):\n",
    "    if x >=8:\n",
    "        return 2\n",
    "    elif x<8 and x>=6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['imdb_score'] = df['imdb_score'].apply(agrupar_pelis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = np.sort(df['imdb_score'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df[df.imdb_score == 0]), len(df[df.imdb_score == 1]),len(df[df.imdb_score == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df['earning_rate'] = df.apply(lambda r: r.gross / r.budget, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_corr = df[a.columns.tolist()]\n",
    "\n",
    "plt.matshow(df_corr.corr())\n",
    "plt.xticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist(), rotation=\"vertical\")\n",
    "plt.yticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ac1 = df['actor_1_name'].unique()\n",
    "ac2 = df['actor_2_name'].unique()\n",
    "ac3 = df['actor_3_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = np.concatenate((ac1, ac2, ac3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = dict(enumerate(set(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorizar(row):\n",
    "    for x in total:\n",
    "        if total[x] == row:\n",
    "            return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['actor_1_name'] = df['actor_1_name'].apply(lambda row: factorizar(row))\n",
    "df['actor_2_name'] = df['actor_2_name'].apply(lambda row: factorizar(row))\n",
    "df['actor_3_name'] = df['actor_3_name'].apply(lambda row: factorizar(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Para obtener los indices de los paises y los lenguajes de las peliculas\n",
    "idx_language, label_language = pd.factorize(df['language'])\n",
    "idx_country, label_country = pd.factorize(df['country'])\n",
    "\n",
    "## Para obtener los indices de los actores\n",
    "#idx_actor1, label_actor1 = pd.factorize(df['actor_1_name'])\n",
    "#idx_actor2, label_actor2 = pd.factorize(df['actor_2_name'])\n",
    "#idx_actor3, label_actor3 = pd.factorize(df['actor_3_name'])\n",
    "\n",
    "## Para obtener el indice del director\n",
    "idx_director, label_director = pd.factorize(df['director_name'])\n",
    "\n",
    "#Para obtener los indices del titulo de las peliculas y el content rating\n",
    "idx_movie, label_movie = pd.factorize(df['movie_title'])\n",
    "idx_content, label_content = pd.factorize(df['content_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Separa los generos en columnas\n",
    "df = pd.concat([df, df.genres.str.get_dummies(sep='|')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_separados = pd.DataFrame()\n",
    "df_separados = pd.concat([df_separados, df.plot_keywords.str.replace('|',' ')],axis=1)\n",
    "\n",
    "stopw = set(stopwords.words('english')) \n",
    "corpus = []\n",
    "for e in df_separados.values:\n",
    "    if type(e[0]) is str:\n",
    "        corpus.append(e[0])\n",
    "corpus1 = \" \".join(corpus)\n",
    "corpus1 = corpus1.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus1 = list(filter(lambda x: not x[0] in stopw, corpus1))\n",
    "corpus1 = set(corpus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vocabulary = corpus1\n",
    "vect = TfidfVectorizer(sublinear_tf=True, max_df=2, analyzer='word', \n",
    "           stop_words=stopw, vocabulary=vocabulary)\n",
    "vect.fit(corpus)\n",
    "#print(dict(zip(vect.get_feature_names(), vect.idf_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformar_keywords(k):\n",
    "    if not type(k) is str:\n",
    "        return 0  \n",
    "    keywords = k.replace('|',\" \")\n",
    "    doc_tfidf = vect.transform([k])\n",
    "    t = doc_tfidf.toarray().sum()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['plot_keywords'] = df['plot_keywords'].apply(lambda row: transformar_keywords(row)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['language'] = idx_language\n",
    "df['country'] = idx_country\n",
    "#df['actor_1_name'] = idx_actor1\n",
    "#df['actor_2_name'] = idx_actor2\n",
    "#df['actor_3_name'] = idx_actor3\n",
    "df['director_name'] = idx_director\n",
    "df['movie_title'] = idx_movie\n",
    "df['content_rating'] = idx_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ys = df['imdb_score']\n",
    "df.drop('imdb_score', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas Dropeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.drop('actor_1_facebook_likes', axis=1, inplace=True)\n",
    "#df.drop('actor_2_facebook_likes', axis=1, inplace=True)\n",
    "#df.drop('actor_3_facebook_likes', axis=1, inplace=True)\n",
    "#df.drop('director_facebook_likes', axis=1, inplace=True)\n",
    "\n",
    "#df.drop('director_name', axis=1, inplace=True)\n",
    "#df.drop('actor_1_name', axis=1, inplace=True)\n",
    "#df.drop('actor_2_name', axis=1, inplace=True)\n",
    "#df.drop('actor_3_name', axis=1, inplace=True)\n",
    "\n",
    "#df.drop('cast_total_facebook_likes', axis=1, inplace=True)\n",
    "#df.drop('movie_facebook_likes', axis=1, inplace=True)\n",
    "#df.drop('budget', axis=1, inplace=True)\n",
    "#df.drop('gross', axis=1, inplace=True)\n",
    "#df.drop('cast_total_facebook_likes', axis=1, inplace=True)\n",
    "#df.drop('plot_keywords', axis=1, inplace=True)\n",
    "df.drop('genres', axis=1, inplace=True)\n",
    "df.drop('movie_imdb_link', axis=1, inplace=True)\n",
    "df.drop('color', axis=1, inplace=True)\n",
    "#df.drop('num_user_for_reviews', axis=1, inplace=True)\n",
    "#df.drop('movie_title', axis=1, inplace=True)\n",
    "#df.drop('content_rating', axis=1, inplace=True)\n",
    "#df.drop('duration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_x = MinMaxScaler([-1,1])\n",
    "xs = std_x.fit_transform(xs.astype(np.float32))\n",
    "std_y = MinMaxScaler([-1, 1])\n",
    "ys = std_y.fit_transform(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = df.corr()\n",
    "\n",
    "df_corr = df[a.columns.tolist()]\n",
    "\n",
    "plt.matshow(df_corr.corr())\n",
    "plt.xticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist(), rotation=\"vertical\")\n",
    "plt.yticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import RandomizedPCA # using randomized Singular Value Decomposition \n",
    "Xp = RandomizedPCA(n_components=35, random_state=1)\n",
    "Xp = Xp.fit_transform(xs)\n",
    "\n",
    "#std_x = MinMaxScaler([-1,1])\n",
    "#xs = std_x.fit_transform(Xp)\n",
    "#std_y = MinMaxScaler([-1,1])\n",
    "#ys = std_y.fit_transform(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Xp.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def plot_matrix(clf, X_test, y_test):\n",
    "    plt.clf()\n",
    "    plt.imshow(confusion_matrix(clf.predict(X_test), y_test),\n",
    "               interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"true label\")\n",
    "    plt.ylabel(\"predicted label\")\n",
    "    plt.show()\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=300,\n",
    "                           max_features=0.2, \n",
    "                           n_jobs=2,\n",
    "                           max_depth=None,\n",
    "                           min_samples_split=1,\n",
    "                           random_state=1).fit(X_train, y_train)\n",
    "print(classification_report(clf.predict(X_test), y_test))\n",
    "print(\"Score over Testing Data {}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Score over Training Data {}\".format(clf.score(X_train, y_train)))\n",
    "plot_matrix(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "cols = len(df.columns)\n",
    "\n",
    "text = list(map(lambda i: df.columns[i], range(cols)))\n",
    "plt.figure(figsize=(20,cols))\n",
    "print(importances[::-1].shape)\n",
    "plt.bar(range(cols),height=importances,  width=1.)\n",
    "plt.xticks(np.arange(0.5, cols, 1.), text, rotation=90)\n",
    "plt.xlim((0, cols))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(random_state=0).fit(X_train, y_train)\n",
    "#print clf.score(X_test, y_test)\n",
    "plot_matrix(clf, X_test, y_test)\n",
    "clf.score(X_test, y_test)\n",
    "print(classification_report(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "sv = SVC(kernel='rbf', cache_size=1000)\n",
    "sv.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(sv.predict(X_test), y_test))\n",
    "print(sv.score(X_test, y_test))\n",
    "plot_matrix(sv, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.nonlinearities import linear, tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers_0 = [\n",
    "                (InputLayer, {'shape': (None, 50)}),\n",
    "                (DenseLayer, {'num_units': 500}),\n",
    "                (DropoutLayer, {'p': 0.5}),\n",
    "                (DenseLayer, {'num_units': 300}),\n",
    "                (DropoutLayer, {'p': 0.3}),\n",
    "                (DenseLayer, {'num_units': 3, 'nonlinearity': softmax}),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdjustVariable(object):\n",
    "    \"\"\"\n",
    "    Used to decreases linearly the learning rate with the number of epochs,\n",
    "    while we the momentum increase.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = np.float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_network(npochs=50, batch_s=10000):\n",
    "    return NeuralNet(\n",
    "        layers=layers_0,\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=theano.shared(np.float32(0.0009)),\n",
    "        update_momentum=theano.shared(np.float32(0.9)),\n",
    "\n",
    "        regression=False,\n",
    "        batch_iterator_train=BatchIterator(batch_size=batch_s),\n",
    "        on_epoch_finished=[\n",
    "            AdjustVariable('update_learning_rate', start=0.009, stop=0.0009),\n",
    "            AdjustVariable('update_momentum', start=0.9, stop=0.9999)\n",
    "        ],\n",
    "        max_epochs=npochs,\n",
    "        verbose=1)\n",
    "\n",
    "net0 = create_network(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#theano.config.profile = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.int32)\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "net0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "train_loss = np.array([i[\"train_loss\"] for i in net0.train_history_])\n",
    "valid_loss = np.array([i[\"valid_loss\"] for i in net0.train_history_])\n",
    "plt.plot(train_loss, '--b', linewidth=2, label=\"{} train\".format(\"net0\"))\n",
    "plt.plot(valid_loss, '-b', linewidth=2, label=\"{} valid\".format(\"net0\"))\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "print(classification_report(net0.predict(X_test), y_test))\n",
    "plot_matrix(net0, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> VER ESTO!! NO ESTA TOMANDO LOS ELEMENTOS DE LAS CLASES 0 Y 2</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(net0.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "246 + 733 + 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "168 + 93 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_test, columns=[\"cero\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df[df.cero == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
