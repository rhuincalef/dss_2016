{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import BatchIterator\n",
    "from lasagne.layers import InputLayer, Conv2DLayer, DropoutLayer,\\\n",
    "    MaxPool2DLayer, DenseLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/leandro/Documentos/Universidad/DSS/dss_2016/TPFINAL/data/imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['earning_rate'] = df.apply(lambda r: r.gross / r.budget, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/matplotlib/collections.py:549: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_corr = df[a.columns.tolist()]\n",
    "\n",
    "plt.matshow(df_corr.corr())\n",
    "plt.xticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist(), rotation=\"vertical\")\n",
    "plt.yticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('movie_imdb_link', axis=1, inplace=True)\n",
    "df.drop('color', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Para obtener los indices de los paises y los lenguajes de las peliculas\n",
    "idx_language, label_language = pd.factorize(df['language'])\n",
    "idx_country, label_country = pd.factorize(df['country'])\n",
    "\n",
    "## Para obtener los indices de los actores\n",
    "idx_actor1, label_actor1 = pd.factorize(df['actor_1_name'])\n",
    "idx_actor2, label_actor2 = pd.factorize(df['actor_2_name'])\n",
    "idx_actor3, label_actor3 = pd.factorize(df['actor_3_name'])\n",
    "\n",
    "## Para obtener el indice del director\n",
    "idx_director, label_director = pd.factorize(df['director_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, df.genres.str.get_dummies(sep='|')], axis=1)\n",
    "df.drop('genres', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se debe realizar etiquetado de los nombres de los actores y directores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_separados = pd.DataFrame()\n",
    "df_separados = pd.concat([df_separados, df.plot_keywords.str.replace('|',' ')],axis=1)\n",
    "\n",
    "stopw = set(stopwords.words('english')) \n",
    "corpus = []\n",
    "for e in df_separados.values:\n",
    "    if type(e[0]) is str:\n",
    "        corpus.append(e[0])\n",
    "corpus1 = \" \".join(corpus)\n",
    "corpus1 = corpus1.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus1 = list(filter(lambda x: not x[0] in stopw, corpus1))\n",
    "corpus1 = set(corpus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=2, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words={'with', 'again', 'in', 'has', 'mightn', 'she', 'very', 'themselves', 'now', 'myself', 'his', 'doing', 'they', 'don', 'herself', 'd', 've', 'most', 'below', 'as', 'mustn', 'into', 'aren', 'or', 'are', 'having', 'haven', 'more', 'where', 'until', 'few', 't', 'on', 'only', 'above', 'you', '...', 'do', 'which', 'under', 'what', 'shan', 'then', 'over', 'our', 'any', 'o', 'just', 'had', 'ours'},\n",
       "        strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary={'flower', 'vhs', 'negotiation', 'lunar', 'city', 'piranha', 'boy', 'katana', 'beastmaster', 'rubber', 'capri', 'closeted', 'paleontologist', 'nottingham', 'brahms', 'lti', 'festival', 'beginning', 'controlled', 'puzzle', 'voyager', 'cash', 'highlands', 'bite', 'name', 'bushwhacker', 'cou...n', 'zealand', 'faun', 'fainting', 'buckingham', 'baptism', 'fortune', 'violence', 'bun', 'paradox'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vocabulary = corpus1\n",
    "vect = TfidfVectorizer(sublinear_tf=True, max_df=2, analyzer='word', \n",
    "           stop_words=stopw, vocabulary=vocabulary)\n",
    "vect.fit(corpus)\n",
    "\n",
    "#print(dict(zip(vect.get_feature_names(), vect.idf_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transformar_keywords(k):\n",
    "    if not type(k) is str:\n",
    "        return 0  \n",
    "    keywords = k.replace('|',\" \")\n",
    "    doc_tfidf = vect.transform([k])\n",
    "    t = doc_tfidf.toarray().sum()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['plot_keywords'] = df['plot_keywords'].apply(lambda row: transformar_keywords(row)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.drop('plot_keywords', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Para obtener los indices del titulo de las peliculas y el content rating\n",
    "idx_movie, label_movie = pd.factorize(df['movie_title'])\n",
    "idx_content, label_content = pd.factorize(df['content_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['language'] = idx_language\n",
    "df['country'] = idx_country\n",
    "df['actor_1_name'] = idx_actor1\n",
    "df['actor_2_name'] = idx_actor2\n",
    "df['actor_3_name'] = idx_actor3\n",
    "df['director_name'] = idx_director\n",
    "df['movie_title'] = idx_movie\n",
    "df['content_rating'] = idx_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ys = df['imdb_score']\n",
    "df.drop('imdb_score', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('actor_2_facebook_likes', axis=1, inplace=True)\n",
    "df.drop('actor_3_facebook_likes', axis=1, inplace=True)\n",
    "#df.drop('cast_total_facebook_likes', axis=1, inplace=True)\n",
    "#df.drop('movie_facebook_likes', axis=1, inplace=True)\n",
    "df.drop('budget', axis=1, inplace=True)\n",
    "df.drop('gross', axis=1, inplace=True)\n",
    "#df.drop(['Film-Noir', 'News', 'Reality-TV', 'Short' ,'History', 'Western', 'Game-Show'], axis=1, inplace=True)\n",
    "\n",
    "#Seleccionado uno de los atributos relevantes.\n",
    "\n",
    "df_test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leandro/virtualenvs/DSS/lib/python3.4/site-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/leandro/virtualenvs/DSS/lib/python3.4/site-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "std_x = MinMaxScaler([-1,1])\n",
    "xs = std_x.fit_transform(xs)\n",
    "std_y = MinMaxScaler([-1,1])\n",
    "ys = std_y.fit_transform(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = df.corr()\n",
    "\n",
    "df_corr = df[a.columns.tolist()]\n",
    "\n",
    "plt.matshow(df_corr.corr())\n",
    "plt.xticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist(), rotation=\"vertical\")\n",
    "plt.yticks(np.arange(0, len(df_corr.columns)), df_corr.columns.tolist())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import RandomizedPCA # using randomized Singular Value Decomposition \n",
    "Xp = RandomizedPCA(n_components=6, random_state=1)\n",
    "Xp = Xp.fit_transform(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys,random_state=1)\n",
    "\n",
    "clf = ExtraTreeRegressor(max_features=0.2,max_depth=None,min_samples_split=1,\n",
    "                           random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreeRegressor(criterion='mse', max_depth=None, max_features=0.2,\n",
       "          max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=1,\n",
       "          min_weight_fraction_leaf=0.0, random_state=1, splitter='random')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.26726152e-02,   3.40951521e-02,   6.59972499e-02,\n",
       "         2.90021106e-02,   2.07074577e-02,   1.70683975e-02,\n",
       "         2.51156147e-02,   2.55721180e-02,   2.13421418e-01,\n",
       "         1.81741322e-02,   2.76795266e-02,   1.50339799e-02,\n",
       "         0.00000000e+00,   2.04493889e-02,   1.23312158e-02,\n",
       "         1.49526626e-02,   2.55400535e-02,   5.71253334e-02,\n",
       "         2.95342999e-02,   2.67458710e-02,   2.07737760e-02,\n",
       "         1.05446284e-02,   7.28749904e-03,   6.85285798e-03,\n",
       "         5.74781600e-03,   1.82045479e-02,   1.08075851e-02,\n",
       "         1.17120589e-02,   7.89956906e-02,   6.74470805e-03,\n",
       "         9.91446865e-03,   2.28188782e-04,   0.00000000e+00,\n",
       "         7.36564970e-03,   1.81600763e-02,   5.05711756e-03,\n",
       "         8.07962731e-03,   7.30579514e-03,   1.03632449e-06,\n",
       "         0.00000000e+00,   1.39534297e-02,   8.42317477e-03,\n",
       "         7.43198528e-04,   9.70474912e-03,   1.59446500e-02,\n",
       "         2.61516282e-03,   3.61391032e-03])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#text = map(lambda i: df.columns[1:-1][i], range(93))\n",
    "text = list(map(lambda i: df.columns[i], range(len(df.columns))))\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.bar(range(len(df.columns)),height=importances,  width=1.)\n",
    "plt.xticks(np.arange(0.5, len(df.columns), 1.), text, rotation=90)\n",
    "plt.xlim((0, len(df.columns)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df[df.columns[-518:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers_0 = [\n",
    "                (InputLayer, {'shape': (None, 47)}),\n",
    "                #(DenseLayer, {'num_units': 256}),\n",
    "                (DenseLayer, {'num_units': 512}),\n",
    "                #(DropoutLayer, {'p' : 0.3}),\n",
    "                (DenseLayer, {'num_units': 512}),\n",
    "                #(DenseLayer, {'num_units': 256}),\n",
    "                #(DropoutLayer, {'p' : 0.3}),\n",
    "                (DenseLayer, {'num_units': 1, 'nonlinearity': None}),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdjustVariable(object):\n",
    "    \"\"\"\n",
    "    Used to decreases linearly the learning rate with the number of epochs,\n",
    "    while we the momentum increase.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = np.float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_network(npochs=100, batch_s=10000):\n",
    "    return NeuralNet(\n",
    "        layers=layers_0,\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=theano.shared(np.float32(0.000003)),\n",
    "        update_momentum=theano.shared(np.float32(0.9)),\n",
    "\n",
    "        regression=True,\n",
    "        #batch_iterator_train=BatchIterator(batch_size=batch_s),\n",
    "        on_epoch_finished=[\n",
    "            AdjustVariable('update_learning_rate', start=0.00003, stop=0.000003),\n",
    "            AdjustVariable('update_momentum', start=0.9, stop=0.9999)\n",
    "        ],\n",
    "        max_epochs=npochs,\n",
    "        verbose=1)\n",
    "\n",
    "net0 = create_network(npochs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#theano.config.profile = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.float32)\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "net0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "train_loss = np.array([i[\"train_loss\"] for i in net0.train_history_])\n",
    "valid_loss = np.array([i[\"valid_loss\"] for i in net0.train_history_])\n",
    "plt.plot(train_loss, '--b', linewidth=2, label=\"{} train\".format(\"net0\"))\n",
    "plt.plot(valid_loss, '-b', linewidth=2, label=\"{} valid\".format(\"net0\"))\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y = y_test.astype(np.float32) \n",
    "\n",
    "x = X_test.astype(np.float32)\n",
    "\n",
    "r2_score(y,net0.predict(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
